{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Implement Multilayer Perceptron Using Keras (Book 2)**"
      ],
      "metadata": {
        "id": "pWyZbKYjJxua"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1c9NQcYHmj3"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input and output variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation= 'relu'))\n",
        "model.add(Dense(8, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIq70O7eJJHS",
        "outputId": "f71c4919-3a8a-48bd-9264-66fae5ac53e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 0.9512 - accuracy: 0.6380\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.6380\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.6263\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.6237\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.6523\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.6562\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.6641\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6641\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.6536\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6719\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6823\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.6810\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.6732\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.6732\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6966\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6940\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.6979\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6810\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6966\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6784\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7070\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6940\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7044\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.7031\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7070\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7096\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.6979\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6992\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7018\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.6979\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6966\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7005\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7096\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7214\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7122\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7109\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7018\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7044\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7148\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7188\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6966\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7253\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7044\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7305\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7201\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7096\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7122\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7240\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7227\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7070\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7227\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7201\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7383\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7214\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7240\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7370\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7174\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7214\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7396\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7109\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7253\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7461\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7344\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7266\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7253\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7435\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7253\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7318\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7161\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7266\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7188\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7409\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7148\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7513\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7396\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7331\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7344\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7474\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7292\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7487\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7357\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7214\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7331\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7370\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7318\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7396\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7279\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7409\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7409\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7578\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7474\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7474\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7526\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7500\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7448\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7487\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7474\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7422\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7435\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7331\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7487\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7461\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7591\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7565\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7318\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7357\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7513\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7513\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7461\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7331\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7370\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7721\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7565\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7422\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7552\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7422\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7487\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7422\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7448\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7396\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7565\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7513\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7461\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7552\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7474\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7461\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7513\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7565\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7396\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7643\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7422\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7526\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7617\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7578\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7630\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7617\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7591\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7474\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7578\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7500\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7604\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7773\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7565\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7539\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7604\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7604\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7591\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7669\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7643\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7539\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7669\n",
            "\n",
            "accuracy: 76.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning using different number of hidden nodes\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation= 'relu'))\n",
        "model.add(Dense(6, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmXZJ_yjWJ9X",
        "outputId": "035777d7-bff8-4337-9533-1f9079f4dace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 2s 3ms/step - loss: 0.9120 - accuracy: 0.6185\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6536\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.6536\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.6576\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6576\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6654\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6758\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6628\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6576\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6680\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6667\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6070 - accuracy: 0.6745\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.6823\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6797\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.6693\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6745\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6706\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6745\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6732\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6719\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6797\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6810\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6784\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6849\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6732\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6797\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6615\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6784\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.6745\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5794 - accuracy: 0.6875\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.6771\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6784\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6732\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.6836\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6797\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6719\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6771\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.6875\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6745\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.6849\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6667\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6927\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6823\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.6888\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.6745\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6823\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6810\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.6784\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6836\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6901\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.6901\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6719\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6810\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6862\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6849\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6771\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.6797\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.6797\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.6771\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6810\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.6862\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.6810\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.6940\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.6810\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.6849\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6836\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.6797\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.6875\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6745\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6888\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.6914\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6836\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.6862\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.6888\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.6784\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5744 - accuracy: 0.6888\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6836\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5713 - accuracy: 0.6771\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.6901\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.6810\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.6888\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.6810\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.6823\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.6849\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.6823\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6797\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.6849\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.6797\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.6693\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.6862\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6823\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.6953\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6836\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.6797\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.6966\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.6862\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6849\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.6823\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.6875\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.6953\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.6888\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.6797\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6849\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.6797\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.6927\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.6823\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6836\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.6836\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.6784\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.6862\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.6836\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.6810\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.6901\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6771\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.6810\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.6901\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.6849\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.6901\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.6940\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.6953\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6875\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6745\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.6862\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.6810\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.6927\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5564 - accuracy: 0.6849\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.6823\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5559 - accuracy: 0.6849\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.6823\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.6836\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.6888\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.6914\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.6797\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.6888\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.6849\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.6797\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.6849\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.6719\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.6810\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.6888\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.6823\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.6862\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.6875\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.6849\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.6953\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.6823\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6836\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.6745\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.6888\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.6888\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.6940\n",
            "\n",
            "accuracy: 69.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning using different number of hidden nodes\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation= 'relu'))\n",
        "model.add(Dense(12, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8247szKXGO2",
        "outputId": "7986b5e1-e324-478c-e611-1b672462480d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 3ms/step - loss: 12.2021 - accuracy: 0.6237\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 2.7115 - accuracy: 0.6003\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.8432 - accuracy: 0.6029\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.2749 - accuracy: 0.5990\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.9708 - accuracy: 0.5859\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.8051 - accuracy: 0.5990\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.6237\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.6224\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.6445\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6650 - accuracy: 0.6445\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6784\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6849\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.6784\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6823\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6523\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6758\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6589\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6836\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6901\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7122\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6823\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6953\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.6497\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.6927\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.6810\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.7135\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6849\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7018\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6758\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7018\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.6927\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6823\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6810\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7083\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7201\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6979\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7240\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7083\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6849\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7201\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6992\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7109\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7174\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7266\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7148\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7266\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7214\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7109\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7070\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7044\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7279\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7044\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7214\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7266\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7031\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7474\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7188\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7240\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7279\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.7266\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7305\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5492 - accuracy: 0.7292\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7396\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7292\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7357\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7461\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7318\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7461\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7292\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7383\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7240\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7448\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7396\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7448\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7448\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7630\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7357\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7370\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7383\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.6979\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7370\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7409\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7214\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7370\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7435\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7370\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7448\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7539\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7461\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7357\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7422\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7344\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7422\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7214\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7292\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7630\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7396\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7448\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7565\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7513\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7474\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7630\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7552\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7448\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7461\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7604\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.7487\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7695\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7435\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7591\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7461\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7565\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7474\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7513\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7643\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7539\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7760\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7565\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7604\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.7721\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7643\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7279\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7604\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7734\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7565\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7578\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7682\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7461\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7656\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7552\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7331\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7643\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7630\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7669\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7617\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7721\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7578\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7695\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7708\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7448\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7643\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7682\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7552\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7721\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7604\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7539\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7578\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7760\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7708\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7474\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7721\n",
            "\n",
            "accuracy: 77.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a Automatic Verification Dataset\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation= 'relu'))\n",
        "model.add(Dense(8, activation= 'relu' ))\n",
        "model.add(Dense(1, activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer='adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Mmt0kxH4R4",
        "outputId": "487ddcbb-b371-4dea-b385-66f060a1fadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "52/52 [==============================] - 2s 18ms/step - loss: 10.3808 - accuracy: 0.6323 - val_loss: 6.5084 - val_accuracy: 0.5827\n",
            "Epoch 2/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 4.8216 - accuracy: 0.6342 - val_loss: 3.3791 - val_accuracy: 0.5433\n",
            "Epoch 3/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 2.2067 - accuracy: 0.5856 - val_loss: 1.4234 - val_accuracy: 0.5118\n",
            "Epoch 4/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.1996 - accuracy: 0.5136 - val_loss: 1.1238 - val_accuracy: 0.5276\n",
            "Epoch 5/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.5661 - val_loss: 0.9514 - val_accuracy: 0.5709\n",
            "Epoch 6/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.9328 - accuracy: 0.5661 - val_loss: 0.9155 - val_accuracy: 0.5512\n",
            "Epoch 7/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.8507 - accuracy: 0.5895 - val_loss: 0.8049 - val_accuracy: 0.6024\n",
            "Epoch 8/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.5973 - val_loss: 0.7662 - val_accuracy: 0.6339\n",
            "Epoch 9/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7634 - accuracy: 0.6051 - val_loss: 0.7525 - val_accuracy: 0.6496\n",
            "Epoch 10/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7285 - accuracy: 0.6284 - val_loss: 0.7754 - val_accuracy: 0.5748\n",
            "Epoch 11/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.7231 - accuracy: 0.6148 - val_loss: 0.6933 - val_accuracy: 0.6890\n",
            "Epoch 12/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.6109 - val_loss: 0.6974 - val_accuracy: 0.6614\n",
            "Epoch 13/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.6459 - val_loss: 0.7107 - val_accuracy: 0.6693\n",
            "Epoch 14/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7174 - accuracy: 0.6187 - val_loss: 0.7085 - val_accuracy: 0.5748\n",
            "Epoch 15/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.6704 - accuracy: 0.6440 - val_loss: 0.6871 - val_accuracy: 0.6811\n",
            "Epoch 16/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.6381 - val_loss: 0.7097 - val_accuracy: 0.5906\n",
            "Epoch 17/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6304 - val_loss: 0.6876 - val_accuracy: 0.6850\n",
            "Epoch 18/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.6381 - val_loss: 0.7031 - val_accuracy: 0.6614\n",
            "Epoch 19/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6673 - val_loss: 0.6743 - val_accuracy: 0.6732\n",
            "Epoch 20/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.6732 - val_loss: 0.6683 - val_accuracy: 0.6417\n",
            "Epoch 21/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.6615 - val_loss: 0.6753 - val_accuracy: 0.6496\n",
            "Epoch 22/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6770 - val_loss: 0.6624 - val_accuracy: 0.5984\n",
            "Epoch 23/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6576 - val_loss: 0.6658 - val_accuracy: 0.6378\n",
            "Epoch 24/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6693 - val_loss: 0.6407 - val_accuracy: 0.6063\n",
            "Epoch 25/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6654 - val_loss: 0.6353 - val_accuracy: 0.6260\n",
            "Epoch 26/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.6654 - val_loss: 0.6660 - val_accuracy: 0.6024\n",
            "Epoch 27/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7062 - val_loss: 0.6793 - val_accuracy: 0.6417\n",
            "Epoch 28/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.6790 - val_loss: 0.7780 - val_accuracy: 0.5591\n",
            "Epoch 29/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6790 - val_loss: 0.6424 - val_accuracy: 0.6732\n",
            "Epoch 30/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.6790 - val_loss: 0.6565 - val_accuracy: 0.6102\n",
            "Epoch 31/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6770 - val_loss: 0.6438 - val_accuracy: 0.6339\n",
            "Epoch 32/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.6654 - val_loss: 0.6440 - val_accuracy: 0.6102\n",
            "Epoch 33/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.6732 - val_loss: 0.6814 - val_accuracy: 0.6063\n",
            "Epoch 34/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6061 - accuracy: 0.7004 - val_loss: 0.6100 - val_accuracy: 0.6654\n",
            "Epoch 35/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.6926 - val_loss: 0.6440 - val_accuracy: 0.6299\n",
            "Epoch 36/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.6907 - val_loss: 0.6562 - val_accuracy: 0.6850\n",
            "Epoch 37/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.7082 - val_loss: 0.6144 - val_accuracy: 0.6614\n",
            "Epoch 38/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.6907 - val_loss: 0.6550 - val_accuracy: 0.6378\n",
            "Epoch 39/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.6965 - val_loss: 0.6334 - val_accuracy: 0.6181\n",
            "Epoch 40/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.6887 - val_loss: 0.6241 - val_accuracy: 0.6535\n",
            "Epoch 41/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6984 - val_loss: 0.6158 - val_accuracy: 0.6260\n",
            "Epoch 42/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6829 - val_loss: 0.6073 - val_accuracy: 0.6811\n",
            "Epoch 43/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.6907 - val_loss: 0.6077 - val_accuracy: 0.6732\n",
            "Epoch 44/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.6868 - val_loss: 0.6538 - val_accuracy: 0.6811\n",
            "Epoch 45/150\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5961 - accuracy: 0.6965 - val_loss: 0.6074 - val_accuracy: 0.6496\n",
            "Epoch 46/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6965 - val_loss: 0.5965 - val_accuracy: 0.6614\n",
            "Epoch 47/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.6790 - val_loss: 0.5923 - val_accuracy: 0.6693\n",
            "Epoch 48/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.6907 - val_loss: 0.5937 - val_accuracy: 0.6693\n",
            "Epoch 49/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6965 - val_loss: 0.6138 - val_accuracy: 0.6772\n",
            "Epoch 50/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.6887 - val_loss: 0.5935 - val_accuracy: 0.6732\n",
            "Epoch 51/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7004 - val_loss: 0.6146 - val_accuracy: 0.6535\n",
            "Epoch 52/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7101 - val_loss: 0.6157 - val_accuracy: 0.6772\n",
            "Epoch 53/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7023 - val_loss: 0.6126 - val_accuracy: 0.6772\n",
            "Epoch 54/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.7062 - val_loss: 0.6088 - val_accuracy: 0.6811\n",
            "Epoch 55/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5710 - accuracy: 0.7082 - val_loss: 0.5970 - val_accuracy: 0.6654\n",
            "Epoch 56/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5672 - accuracy: 0.7121 - val_loss: 0.5860 - val_accuracy: 0.6693\n",
            "Epoch 57/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.6926 - val_loss: 0.6032 - val_accuracy: 0.6614\n",
            "Epoch 58/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5758 - accuracy: 0.7101 - val_loss: 0.5744 - val_accuracy: 0.7087\n",
            "Epoch 59/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.6809 - val_loss: 0.5951 - val_accuracy: 0.6850\n",
            "Epoch 60/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.5633 - accuracy: 0.7121 - val_loss: 0.5777 - val_accuracy: 0.6929\n",
            "Epoch 61/150\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.5846 - accuracy: 0.7121 - val_loss: 0.5789 - val_accuracy: 0.7126\n",
            "Epoch 62/150\n",
            "52/52 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.6965 - val_loss: 0.6009 - val_accuracy: 0.6890\n",
            "Epoch 63/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5809 - accuracy: 0.6965 - val_loss: 0.5839 - val_accuracy: 0.6929\n",
            "Epoch 64/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.7121 - val_loss: 0.5960 - val_accuracy: 0.6929\n",
            "Epoch 65/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5716 - accuracy: 0.7043 - val_loss: 0.6088 - val_accuracy: 0.6811\n",
            "Epoch 66/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5669 - accuracy: 0.6868 - val_loss: 0.5743 - val_accuracy: 0.6969\n",
            "Epoch 67/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.5944 - accuracy: 0.7101 - val_loss: 0.6190 - val_accuracy: 0.6850\n",
            "Epoch 68/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5729 - accuracy: 0.7043 - val_loss: 0.5769 - val_accuracy: 0.6772\n",
            "Epoch 69/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7335 - val_loss: 0.6073 - val_accuracy: 0.6969\n",
            "Epoch 70/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7043 - val_loss: 0.6094 - val_accuracy: 0.7047\n",
            "Epoch 71/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.7121 - val_loss: 0.5765 - val_accuracy: 0.6929\n",
            "Epoch 72/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.6848 - val_loss: 0.5791 - val_accuracy: 0.7047\n",
            "Epoch 73/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7179 - val_loss: 0.5944 - val_accuracy: 0.7008\n",
            "Epoch 74/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.6926 - val_loss: 0.5583 - val_accuracy: 0.7126\n",
            "Epoch 75/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7043 - val_loss: 0.5723 - val_accuracy: 0.7126\n",
            "Epoch 76/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.6965 - val_loss: 0.5682 - val_accuracy: 0.6772\n",
            "Epoch 77/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.6984 - val_loss: 0.5682 - val_accuracy: 0.6890\n",
            "Epoch 78/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7062 - val_loss: 0.5491 - val_accuracy: 0.7165\n",
            "Epoch 79/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7004 - val_loss: 0.5753 - val_accuracy: 0.7087\n",
            "Epoch 80/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.7257 - val_loss: 0.5614 - val_accuracy: 0.7165\n",
            "Epoch 81/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7004 - val_loss: 0.5588 - val_accuracy: 0.6929\n",
            "Epoch 82/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.7198 - val_loss: 0.5538 - val_accuracy: 0.7205\n",
            "Epoch 83/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5556 - accuracy: 0.7023 - val_loss: 0.5623 - val_accuracy: 0.7126\n",
            "Epoch 84/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.6907 - val_loss: 0.5558 - val_accuracy: 0.7205\n",
            "Epoch 85/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7160 - val_loss: 0.5625 - val_accuracy: 0.7244\n",
            "Epoch 86/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.6984 - val_loss: 0.6335 - val_accuracy: 0.6811\n",
            "Epoch 87/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7062 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
            "Epoch 88/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7179 - val_loss: 0.5509 - val_accuracy: 0.7126\n",
            "Epoch 89/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7101 - val_loss: 0.5659 - val_accuracy: 0.7244\n",
            "Epoch 90/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7062 - val_loss: 0.5922 - val_accuracy: 0.7087\n",
            "Epoch 91/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7160 - val_loss: 0.5482 - val_accuracy: 0.7362\n",
            "Epoch 92/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7043 - val_loss: 0.5611 - val_accuracy: 0.7244\n",
            "Epoch 93/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7179 - val_loss: 0.5905 - val_accuracy: 0.7126\n",
            "Epoch 94/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7257 - val_loss: 0.5498 - val_accuracy: 0.7362\n",
            "Epoch 95/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7257 - val_loss: 0.5627 - val_accuracy: 0.7205\n",
            "Epoch 96/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7121 - val_loss: 0.5481 - val_accuracy: 0.7323\n",
            "Epoch 97/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7257 - val_loss: 0.5436 - val_accuracy: 0.7283\n",
            "Epoch 98/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7276 - val_loss: 0.5680 - val_accuracy: 0.7362\n",
            "Epoch 99/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5476 - accuracy: 0.7062 - val_loss: 0.5541 - val_accuracy: 0.7244\n",
            "Epoch 100/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5423 - accuracy: 0.7257 - val_loss: 0.5463 - val_accuracy: 0.7126\n",
            "Epoch 101/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5552 - accuracy: 0.7023 - val_loss: 0.5984 - val_accuracy: 0.6969\n",
            "Epoch 102/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.7043 - val_loss: 0.5659 - val_accuracy: 0.7126\n",
            "Epoch 103/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5478 - accuracy: 0.7140 - val_loss: 0.5353 - val_accuracy: 0.7205\n",
            "Epoch 104/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7101 - val_loss: 0.5558 - val_accuracy: 0.7008\n",
            "Epoch 105/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5515 - accuracy: 0.7121 - val_loss: 0.5486 - val_accuracy: 0.7244\n",
            "Epoch 106/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7276 - val_loss: 0.5481 - val_accuracy: 0.7283\n",
            "Epoch 107/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7198 - val_loss: 0.5366 - val_accuracy: 0.7362\n",
            "Epoch 108/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7218 - val_loss: 0.5412 - val_accuracy: 0.7362\n",
            "Epoch 109/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7101 - val_loss: 0.5660 - val_accuracy: 0.7244\n",
            "Epoch 110/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7218 - val_loss: 0.5652 - val_accuracy: 0.7205\n",
            "Epoch 111/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7121 - val_loss: 0.5625 - val_accuracy: 0.7205\n",
            "Epoch 112/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7101 - val_loss: 0.5361 - val_accuracy: 0.7559\n",
            "Epoch 113/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7296 - val_loss: 0.5409 - val_accuracy: 0.7362\n",
            "Epoch 114/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7257 - val_loss: 0.5693 - val_accuracy: 0.7087\n",
            "Epoch 115/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7237 - val_loss: 0.5790 - val_accuracy: 0.7205\n",
            "Epoch 116/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7354 - val_loss: 0.5481 - val_accuracy: 0.7244\n",
            "Epoch 117/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7354 - val_loss: 0.5258 - val_accuracy: 0.7441\n",
            "Epoch 118/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.7296 - val_loss: 0.5474 - val_accuracy: 0.7480\n",
            "Epoch 119/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7257 - val_loss: 0.5351 - val_accuracy: 0.7441\n",
            "Epoch 120/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7198 - val_loss: 0.5586 - val_accuracy: 0.7362\n",
            "Epoch 121/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7121 - val_loss: 0.5549 - val_accuracy: 0.7283\n",
            "Epoch 122/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.6984 - val_loss: 0.5454 - val_accuracy: 0.7323\n",
            "Epoch 123/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7198 - val_loss: 0.5591 - val_accuracy: 0.7323\n",
            "Epoch 124/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7257 - val_loss: 0.5241 - val_accuracy: 0.7559\n",
            "Epoch 125/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7198 - val_loss: 0.5567 - val_accuracy: 0.7559\n",
            "Epoch 126/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7257 - val_loss: 0.5424 - val_accuracy: 0.7402\n",
            "Epoch 127/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7237 - val_loss: 0.5415 - val_accuracy: 0.7441\n",
            "Epoch 128/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7198 - val_loss: 0.5331 - val_accuracy: 0.7520\n",
            "Epoch 129/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7354 - val_loss: 0.5551 - val_accuracy: 0.7323\n",
            "Epoch 130/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7237 - val_loss: 0.5342 - val_accuracy: 0.7323\n",
            "Epoch 131/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5192 - accuracy: 0.7218 - val_loss: 0.6018 - val_accuracy: 0.6850\n",
            "Epoch 132/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7140 - val_loss: 0.5305 - val_accuracy: 0.7520\n",
            "Epoch 133/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7218 - val_loss: 0.5342 - val_accuracy: 0.7480\n",
            "Epoch 134/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7354 - val_loss: 0.5761 - val_accuracy: 0.7205\n",
            "Epoch 135/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7140 - val_loss: 0.5165 - val_accuracy: 0.7402\n",
            "Epoch 136/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7315 - val_loss: 0.5656 - val_accuracy: 0.7244\n",
            "Epoch 137/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7296 - val_loss: 0.5133 - val_accuracy: 0.7480\n",
            "Epoch 138/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7393 - val_loss: 0.5602 - val_accuracy: 0.7087\n",
            "Epoch 139/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7432 - val_loss: 0.5158 - val_accuracy: 0.7559\n",
            "Epoch 140/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7257 - val_loss: 0.5581 - val_accuracy: 0.7402\n",
            "Epoch 141/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7374 - val_loss: 0.5172 - val_accuracy: 0.7520\n",
            "Epoch 142/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7257 - val_loss: 0.5125 - val_accuracy: 0.7520\n",
            "Epoch 143/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7315 - val_loss: 0.5230 - val_accuracy: 0.7520\n",
            "Epoch 144/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7451 - val_loss: 0.5359 - val_accuracy: 0.7362\n",
            "Epoch 145/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7412 - val_loss: 0.5305 - val_accuracy: 0.7402\n",
            "Epoch 146/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7393 - val_loss: 0.5189 - val_accuracy: 0.7323\n",
            "Epoch 147/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.7393 - val_loss: 0.5314 - val_accuracy: 0.7205\n",
            "Epoch 148/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5196 - accuracy: 0.7412 - val_loss: 0.5146 - val_accuracy: 0.7598\n",
            "Epoch 149/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5096 - accuracy: 0.7549 - val_loss: 0.5927 - val_accuracy: 0.7087\n",
            "Epoch 150/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7218 - val_loss: 0.5178 - val_accuracy: 0.7598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc5521add0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP with manual validation set\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# split into 67% for train and 33% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation= 'relu'))\n",
        "model.add(Dense(8, activation= 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "# Compile model\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"
      ],
      "metadata": {
        "id": "TS1yZ6gZIBgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771651cb-ef93-4e90-b6a0-c43194384e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "52/52 [==============================] - 2s 8ms/step - loss: 6.8117 - accuracy: 0.6245 - val_loss: 4.0671 - val_accuracy: 0.6299\n",
            "Epoch 2/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 2.7318 - accuracy: 0.6498 - val_loss: 2.5383 - val_accuracy: 0.6732\n",
            "Epoch 3/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.6681 - accuracy: 0.6362 - val_loss: 1.4508 - val_accuracy: 0.6693\n",
            "Epoch 4/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 1.1651 - accuracy: 0.6556 - val_loss: 1.1409 - val_accuracy: 0.6614\n",
            "Epoch 5/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 1.0389 - accuracy: 0.6362 - val_loss: 1.0684 - val_accuracy: 0.6811\n",
            "Epoch 6/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.9810 - accuracy: 0.6518 - val_loss: 1.2197 - val_accuracy: 0.6693\n",
            "Epoch 7/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.9585 - accuracy: 0.6381 - val_loss: 1.1518 - val_accuracy: 0.6811\n",
            "Epoch 8/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.8795 - accuracy: 0.6537 - val_loss: 0.8809 - val_accuracy: 0.6535\n",
            "Epoch 9/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.8988 - accuracy: 0.6459 - val_loss: 0.8628 - val_accuracy: 0.6732\n",
            "Epoch 10/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.8142 - accuracy: 0.6868 - val_loss: 0.8567 - val_accuracy: 0.5709\n",
            "Epoch 11/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7978 - accuracy: 0.6615 - val_loss: 0.7854 - val_accuracy: 0.6378\n",
            "Epoch 12/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7920 - accuracy: 0.6615 - val_loss: 0.7990 - val_accuracy: 0.6811\n",
            "Epoch 13/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7497 - accuracy: 0.6673 - val_loss: 0.7650 - val_accuracy: 0.6457\n",
            "Epoch 14/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.6595 - val_loss: 0.7533 - val_accuracy: 0.6614\n",
            "Epoch 15/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.7173 - accuracy: 0.6751 - val_loss: 0.7650 - val_accuracy: 0.6024\n",
            "Epoch 16/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.6537 - val_loss: 0.7560 - val_accuracy: 0.6024\n",
            "Epoch 17/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7481 - accuracy: 0.6518 - val_loss: 0.7890 - val_accuracy: 0.6811\n",
            "Epoch 18/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.7039 - accuracy: 0.6790 - val_loss: 0.8163 - val_accuracy: 0.6811\n",
            "Epoch 19/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.7006 - accuracy: 0.6673 - val_loss: 0.7114 - val_accuracy: 0.6535\n",
            "Epoch 20/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.6732 - val_loss: 0.6942 - val_accuracy: 0.6339\n",
            "Epoch 21/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6654 - val_loss: 0.6819 - val_accuracy: 0.6850\n",
            "Epoch 22/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.6518 - val_loss: 0.6835 - val_accuracy: 0.6850\n",
            "Epoch 23/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6790 - val_loss: 0.6687 - val_accuracy: 0.6496\n",
            "Epoch 24/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.7082 - val_loss: 0.6737 - val_accuracy: 0.6811\n",
            "Epoch 25/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6790 - val_loss: 0.6553 - val_accuracy: 0.6496\n",
            "Epoch 26/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.7004 - val_loss: 0.6791 - val_accuracy: 0.6811\n",
            "Epoch 27/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.7101 - val_loss: 0.7850 - val_accuracy: 0.6299\n",
            "Epoch 28/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6790 - val_loss: 0.6239 - val_accuracy: 0.6890\n",
            "Epoch 29/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6036 - accuracy: 0.6868 - val_loss: 0.6738 - val_accuracy: 0.6299\n",
            "Epoch 30/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6965 - val_loss: 0.6248 - val_accuracy: 0.6614\n",
            "Epoch 31/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5893 - accuracy: 0.7004 - val_loss: 0.6192 - val_accuracy: 0.6535\n",
            "Epoch 32/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.6907 - val_loss: 0.7058 - val_accuracy: 0.6850\n",
            "Epoch 33/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7043 - val_loss: 0.5975 - val_accuracy: 0.6732\n",
            "Epoch 34/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.7023 - val_loss: 0.6566 - val_accuracy: 0.6575\n",
            "Epoch 35/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.6946 - val_loss: 0.7420 - val_accuracy: 0.6575\n",
            "Epoch 36/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7198 - val_loss: 0.6283 - val_accuracy: 0.6929\n",
            "Epoch 37/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7276 - val_loss: 0.6355 - val_accuracy: 0.6654\n",
            "Epoch 38/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.7160 - val_loss: 0.6201 - val_accuracy: 0.6811\n",
            "Epoch 39/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5993 - accuracy: 0.7043 - val_loss: 0.6135 - val_accuracy: 0.6732\n",
            "Epoch 40/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5617 - accuracy: 0.7121 - val_loss: 0.6943 - val_accuracy: 0.6772\n",
            "Epoch 41/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5837 - accuracy: 0.7023 - val_loss: 0.6555 - val_accuracy: 0.6732\n",
            "Epoch 42/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.5928 - accuracy: 0.7237 - val_loss: 0.6134 - val_accuracy: 0.6890\n",
            "Epoch 43/150\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5595 - accuracy: 0.7374 - val_loss: 0.7151 - val_accuracy: 0.6220\n",
            "Epoch 44/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.7004 - val_loss: 0.6550 - val_accuracy: 0.6850\n",
            "Epoch 45/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7315 - val_loss: 0.6295 - val_accuracy: 0.6772\n",
            "Epoch 46/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.7004 - val_loss: 0.7124 - val_accuracy: 0.6654\n",
            "Epoch 47/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7179 - val_loss: 0.6836 - val_accuracy: 0.6772\n",
            "Epoch 48/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7198 - val_loss: 0.6068 - val_accuracy: 0.7047\n",
            "Epoch 49/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7140 - val_loss: 0.5950 - val_accuracy: 0.6811\n",
            "Epoch 50/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5667 - accuracy: 0.7218 - val_loss: 0.6169 - val_accuracy: 0.6811\n",
            "Epoch 51/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5913 - accuracy: 0.7004 - val_loss: 0.6154 - val_accuracy: 0.7008\n",
            "Epoch 52/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7276 - val_loss: 0.6199 - val_accuracy: 0.7008\n",
            "Epoch 53/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7237 - val_loss: 0.6262 - val_accuracy: 0.6969\n",
            "Epoch 54/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7393 - val_loss: 0.6095 - val_accuracy: 0.6850\n",
            "Epoch 55/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7198 - val_loss: 0.5947 - val_accuracy: 0.7008\n",
            "Epoch 56/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7296 - val_loss: 0.6247 - val_accuracy: 0.6969\n",
            "Epoch 57/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7451 - val_loss: 0.7669 - val_accuracy: 0.6496\n",
            "Epoch 58/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7004 - val_loss: 0.6445 - val_accuracy: 0.6772\n",
            "Epoch 59/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7237 - val_loss: 0.6090 - val_accuracy: 0.6890\n",
            "Epoch 60/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7354 - val_loss: 0.6063 - val_accuracy: 0.6890\n",
            "Epoch 61/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7393 - val_loss: 0.6836 - val_accuracy: 0.6614\n",
            "Epoch 62/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7237 - val_loss: 0.6235 - val_accuracy: 0.6890\n",
            "Epoch 63/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7335 - val_loss: 0.6224 - val_accuracy: 0.7087\n",
            "Epoch 64/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7315 - val_loss: 0.5982 - val_accuracy: 0.7087\n",
            "Epoch 65/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7432 - val_loss: 0.6616 - val_accuracy: 0.6339\n",
            "Epoch 66/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7296 - val_loss: 0.5843 - val_accuracy: 0.6890\n",
            "Epoch 67/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7354 - val_loss: 0.5904 - val_accuracy: 0.6772\n",
            "Epoch 68/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7237 - val_loss: 0.6444 - val_accuracy: 0.6575\n",
            "Epoch 69/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7471 - val_loss: 0.8264 - val_accuracy: 0.6457\n",
            "Epoch 70/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6829 - val_loss: 0.6682 - val_accuracy: 0.6811\n",
            "Epoch 71/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.7296 - val_loss: 0.6029 - val_accuracy: 0.7008\n",
            "Epoch 72/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7276 - val_loss: 0.6029 - val_accuracy: 0.6890\n",
            "Epoch 73/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6868 - val_loss: 0.7298 - val_accuracy: 0.6142\n",
            "Epoch 74/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7568 - val_loss: 0.6428 - val_accuracy: 0.6693\n",
            "Epoch 75/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7160 - val_loss: 0.5859 - val_accuracy: 0.7165\n",
            "Epoch 76/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7510 - val_loss: 0.5849 - val_accuracy: 0.7087\n",
            "Epoch 77/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7354 - val_loss: 0.5839 - val_accuracy: 0.7047\n",
            "Epoch 78/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7237 - val_loss: 0.6179 - val_accuracy: 0.6890\n",
            "Epoch 79/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7315 - val_loss: 0.6875 - val_accuracy: 0.6299\n",
            "Epoch 80/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7471 - val_loss: 0.6128 - val_accuracy: 0.6890\n",
            "Epoch 81/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7276 - val_loss: 0.5884 - val_accuracy: 0.6969\n",
            "Epoch 82/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7549 - val_loss: 0.6006 - val_accuracy: 0.6969\n",
            "Epoch 83/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7451 - val_loss: 0.5935 - val_accuracy: 0.7087\n",
            "Epoch 84/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.7451 - val_loss: 0.5764 - val_accuracy: 0.7205\n",
            "Epoch 85/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.5152 - accuracy: 0.7763 - val_loss: 0.6078 - val_accuracy: 0.7126\n",
            "Epoch 86/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.7393 - val_loss: 0.5834 - val_accuracy: 0.7047\n",
            "Epoch 87/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5470 - accuracy: 0.7451 - val_loss: 0.5843 - val_accuracy: 0.7165\n",
            "Epoch 88/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.7685 - val_loss: 0.5784 - val_accuracy: 0.6929\n",
            "Epoch 89/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7568 - val_loss: 0.5846 - val_accuracy: 0.6969\n",
            "Epoch 90/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7315 - val_loss: 0.5843 - val_accuracy: 0.7008\n",
            "Epoch 91/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7451 - val_loss: 0.6329 - val_accuracy: 0.6850\n",
            "Epoch 92/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7471 - val_loss: 0.6679 - val_accuracy: 0.6417\n",
            "Epoch 93/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7374 - val_loss: 0.5687 - val_accuracy: 0.7126\n",
            "Epoch 94/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7335 - val_loss: 0.5859 - val_accuracy: 0.7244\n",
            "Epoch 95/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7588 - val_loss: 0.6027 - val_accuracy: 0.6890\n",
            "Epoch 96/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.7315 - val_loss: 0.6042 - val_accuracy: 0.7008\n",
            "Epoch 97/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7237 - val_loss: 0.7925 - val_accuracy: 0.6535\n",
            "Epoch 98/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.7276 - val_loss: 0.6411 - val_accuracy: 0.6654\n",
            "Epoch 99/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7432 - val_loss: 0.7117 - val_accuracy: 0.5984\n",
            "Epoch 100/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7101 - val_loss: 0.5697 - val_accuracy: 0.7244\n",
            "Epoch 101/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7529 - val_loss: 0.7057 - val_accuracy: 0.6732\n",
            "Epoch 102/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7490 - val_loss: 0.5823 - val_accuracy: 0.7283\n",
            "Epoch 103/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7276 - val_loss: 0.5750 - val_accuracy: 0.7283\n",
            "Epoch 104/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7451 - val_loss: 0.6000 - val_accuracy: 0.6850\n",
            "Epoch 105/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7529 - val_loss: 0.6142 - val_accuracy: 0.7008\n",
            "Epoch 106/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7529 - val_loss: 0.5792 - val_accuracy: 0.7205\n",
            "Epoch 107/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7549 - val_loss: 0.6816 - val_accuracy: 0.6811\n",
            "Epoch 108/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7529 - val_loss: 0.6037 - val_accuracy: 0.6850\n",
            "Epoch 109/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.7471 - val_loss: 0.6290 - val_accuracy: 0.6772\n",
            "Epoch 110/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7626 - val_loss: 0.5852 - val_accuracy: 0.7126\n",
            "Epoch 111/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7315 - val_loss: 0.7464 - val_accuracy: 0.6496\n",
            "Epoch 112/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7412 - val_loss: 0.6333 - val_accuracy: 0.7087\n",
            "Epoch 113/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7685 - val_loss: 0.6369 - val_accuracy: 0.6535\n",
            "Epoch 114/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7354 - val_loss: 0.5951 - val_accuracy: 0.6929\n",
            "Epoch 115/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7549 - val_loss: 0.6000 - val_accuracy: 0.6890\n",
            "Epoch 116/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7665 - val_loss: 0.5673 - val_accuracy: 0.7087\n",
            "Epoch 117/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7549 - val_loss: 0.6141 - val_accuracy: 0.6969\n",
            "Epoch 118/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7451 - val_loss: 0.5914 - val_accuracy: 0.7047\n",
            "Epoch 119/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7549 - val_loss: 0.6376 - val_accuracy: 0.7047\n",
            "Epoch 120/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7198 - val_loss: 0.5676 - val_accuracy: 0.7047\n",
            "Epoch 121/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7393 - val_loss: 0.6183 - val_accuracy: 0.6969\n",
            "Epoch 122/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7432 - val_loss: 0.5885 - val_accuracy: 0.7283\n",
            "Epoch 123/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7471 - val_loss: 0.7831 - val_accuracy: 0.6496\n",
            "Epoch 124/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7451 - val_loss: 0.5884 - val_accuracy: 0.7008\n",
            "Epoch 125/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7510 - val_loss: 0.6103 - val_accuracy: 0.6850\n",
            "Epoch 126/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7763 - val_loss: 0.7430 - val_accuracy: 0.6575\n",
            "Epoch 127/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7626 - val_loss: 0.7022 - val_accuracy: 0.6654\n",
            "Epoch 128/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5133 - accuracy: 0.7510 - val_loss: 0.5700 - val_accuracy: 0.7244\n",
            "Epoch 129/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7529 - val_loss: 0.6102 - val_accuracy: 0.7205\n",
            "Epoch 130/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7490 - val_loss: 0.5773 - val_accuracy: 0.7008\n",
            "Epoch 131/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7763 - val_loss: 0.6383 - val_accuracy: 0.6811\n",
            "Epoch 132/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.7471 - val_loss: 0.6033 - val_accuracy: 0.7087\n",
            "Epoch 133/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4988 - accuracy: 0.7510 - val_loss: 0.5676 - val_accuracy: 0.7126\n",
            "Epoch 134/150\n",
            "52/52 [==============================] - 0s 7ms/step - loss: 0.4879 - accuracy: 0.7665 - val_loss: 0.5829 - val_accuracy: 0.7244\n",
            "Epoch 135/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.4838 - accuracy: 0.7685 - val_loss: 0.5680 - val_accuracy: 0.7126\n",
            "Epoch 136/150\n",
            "52/52 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.7101 - val_loss: 0.7897 - val_accuracy: 0.6496\n",
            "Epoch 137/150\n",
            "52/52 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7471 - val_loss: 0.6024 - val_accuracy: 0.6929\n",
            "Epoch 138/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5185 - accuracy: 0.7354 - val_loss: 0.5822 - val_accuracy: 0.7126\n",
            "Epoch 139/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7646 - val_loss: 0.5928 - val_accuracy: 0.6929\n",
            "Epoch 140/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7685 - val_loss: 0.6062 - val_accuracy: 0.6929\n",
            "Epoch 141/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7529 - val_loss: 0.7798 - val_accuracy: 0.6457\n",
            "Epoch 142/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7588 - val_loss: 0.5804 - val_accuracy: 0.7402\n",
            "Epoch 143/150\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7665 - val_loss: 0.6685 - val_accuracy: 0.6614\n",
            "Epoch 144/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7471 - val_loss: 0.5853 - val_accuracy: 0.7126\n",
            "Epoch 145/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4908 - accuracy: 0.7471 - val_loss: 0.5798 - val_accuracy: 0.7441\n",
            "Epoch 146/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7763 - val_loss: 0.6263 - val_accuracy: 0.7047\n",
            "Epoch 147/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7335 - val_loss: 0.5909 - val_accuracy: 0.6811\n",
            "Epoch 148/150\n",
            "52/52 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7724 - val_loss: 0.6159 - val_accuracy: 0.7047\n",
            "Epoch 149/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7665 - val_loss: 0.5813 - val_accuracy: 0.6850\n",
            "Epoch 150/150\n",
            "52/52 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7724 - val_loss: 0.5913 - val_accuracy: 0.7165\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc551d2560>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, activation= 'relu' ))\n",
        "  model.add(Dense(8, activation= 'relu' ))\n",
        "  model.add(Dense(1, activation= 'sigmoid' ))\n",
        "\n",
        "# Compile model\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
        "\n",
        "# Fit the model\n",
        "  model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "  scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "metadata": {
        "id": "0N4tEbT7ICWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd97b95-da7a-4e06-dbfc-f95925a12c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 71.43%\n",
            "accuracy: 79.22%\n",
            "accuracy: 76.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 3910 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc8de283a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 68.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc55781fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 68.83%\n",
            "accuracy: 66.23%\n",
            "accuracy: 62.34%\n",
            "accuracy: 76.62%\n",
            "accuracy: 71.05%\n",
            "accuracy: 78.95%\n",
            "72.01% (+/- 5.40%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
        "import numpy\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, activation= 'relu'))\n",
        "  model.add(Dense(8, activation= 'relu' ))\n",
        "  model.add(Dense(1, activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "  return model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate using 10-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "3JAM_d0jIHzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46ab439-e8eb-435d-a8cb-c3c7c229b7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-9e895b0911c5>:22: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7226418316364288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grid Search Deep Learning Model Parameters\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer= 'rmsprop' , init= 'glorot_uniform' ):\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, kernel_initializer=init, activation= 'relu' ))\n",
        "  model.add(Dense(8, kernel_initializer=init, activation= 'relu' ))\n",
        "  model.add(Dense(1, kernel_initializer=init, activation= 'sigmoid' ))\n",
        "# Compile model\n",
        "  model.compile(loss= 'binary_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
        "  return model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# grid search epochs, batch size and optimizer\n",
        "optimizers = [ 'adam' ]\n",
        "inits = ['glorot_uniform' , 'uniform' ]\n",
        "epochs = [50, 100]\n",
        "batches = [5, 10]\n",
        "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches, init=inits)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X, Y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "sqZ27RRdINM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fcf3d4-014d-4943-99b3-bc72682f2a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-5c2ea18334aa>:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.744843 using {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.681037 (0.040335) with: {'batch_size': 5, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.708395 (0.037651) with: {'batch_size': 5, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.714905 (0.047058) with: {'batch_size': 5, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.744843 (0.027236) with: {'batch_size': 5, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.684959 (0.049131) with: {'batch_size': 10, 'epochs': 50, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.679705 (0.025555) with: {'batch_size': 10, 'epochs': 50, 'init': 'uniform', 'optimizer': 'adam'}\n",
            "0.699304 (0.031453) with: {'batch_size': 10, 'epochs': 100, 'init': 'glorot_uniform', 'optimizer': 'adam'}\n",
            "0.743511 (0.018346) with: {'batch_size': 10, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation of Multilayer Perceptron using Keras on the Iris Dataset"
      ],
      "metadata": {
        "id": "QAmh3WzXVjNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "import numpy\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "jIBXnZJ2UICE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset\n",
        "dataframe = read_csv(\"iris.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "X = dataset[:,0:4].astype(float)\n",
        "Y = dataset[:,4]"
      ],
      "metadata": {
        "id": "z04WUr7sVMmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "metadata": {
        "id": "xS8ti43SVwap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(8, input_dim=4, activation='relu' ))\n",
        "  model.add(Dense(3, activation= 'softmax' ))\n",
        "# Compile model\n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "StihegGjWAOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gQfN3fyWQ8m",
        "outputId": "ba6818f0-1704-45aa-f159-788b04190436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-282219df88fd>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fce14d40ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fce14b09510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.67% (4.47%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning epoch = 100\n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IojAygLuXdxz",
        "outputId": "ead303f9-d1a1-46f7-bee6-5f70035a1da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0891a324189b>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.67% (9.80%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning epoch = 500\n",
        "estimator = KerasClassifier(build_fn=baseline_model, epochs=500, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzgNIx0CZ0kN",
        "outputId": "6bae0bb8-1936-4811-a064-90b2c4752be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-aff61c2f8332>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimator = KerasClassifier(build_fn=baseline_model, epochs=500, batch_size=5, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.00% (5.33%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model2():\n",
        "# create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(6, input_dim=4, activation='relu' ))\n",
        "  model.add(Dense(3, activation= 'softmax' ))\n",
        "# Compile model\n",
        "  model.compile(loss= 'categorical_crossentropy' , optimizer= 'adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "PJJyHmNJckbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning 1\n",
        "estimator = KerasClassifier(build_fn=baseline_model2, epochs=500, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VwwsGv8c4ni",
        "outputId": "ce8c325e-adde-4905-ca7a-7911142caabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0afd1779b0c3>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimator = KerasClassifier(build_fn=baseline_model2, epochs=500, batch_size=5, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.00% (3.06%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning 2\n",
        "estimator = KerasClassifier(build_fn=baseline_model2, epochs=200, batch_size=5, verbose=0)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbXgdgIYfJL0",
        "outputId": "02af0f2c-4cdf-4f8f-cbd1-a6c5bc9b164b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-a8ca8e949846>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimator = KerasClassifier(build_fn=baseline_model2, epochs=200, batch_size=5, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.00% (21.55%)\n"
          ]
        }
      ]
    }
  ]
}